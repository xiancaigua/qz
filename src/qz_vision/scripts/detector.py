#!/usr/bin/env python3.6
# -*- coding: utf-8 -*-

import cv2
from cv_bridge import CvBridge,CvBridgeError
import rospy
import sys
import queue
import numpy as np
import signal
from ackermann_msgs.msg import AckermannDrive
from geometry_msgs.msg import Twist
from sensor_msgs.msg import Image
import std_msgs.msg as std_msgs
from dynamic_reconfigure.server import Server
from qz_vision.cfg import detector_dynamicConfig
from geometry_msgs.msg import PoseWithCovarianceStamped
from yolo_detect.detect import Detect
import time

"""
Så¼¯é“ç”¨çš„å‚æ•°
"""
# è¯†åˆ«æ ‡å¿—ä½
recog_flag=False
dwa_flag = False
turn_on_recog_flag_flag=True
turn_on_dwa_flag_flag=True
lower1=np.array([0,90,46])
upper1=np.array([10,255,255])
lower2=np.array([156,43,46])
upper2=np.array([180,255,255])

# Så¼¯è“è‰²å—
lowerline=np.array([90, 43, 50])
upperline=np.array( [255, 255, 255])
# Så¼¯çº¢è‰²å—
lowerred2line = np.array( [0,43,255 ] )
upperred2line = np.array( [10,255,255 ] )
# Så¼¯ç™½è‰²å—
lowerwhite=np.array([0, 0, 100])
upperwhite=np.array( [180, 20, 255])
# Så¼¯ç»¿è‰²å—   # 81  46  60
Slowergreen = np.array([50,40,45])
Shighgreen = np.array([90,255,255])

threshofwhite = 100
kernel_size=8
roadlineflag=True # åˆ¤æ–­æ˜¯å¦è¿˜ä½¿ç”¨Så¼¯é“   
queue_out=None


"""
çº¢ç»¿ç¯ç”¨çš„å‚æ•°
"""
break_flag=False
pub_flag=0
color_dict = {
    'Green':[[65, 80, 145], [77, 255, 255]],
    'RandY':[[0, 30, 50], [35, 255, 255]]
}
# color_dict = {
# 	'Green':[[40, 50, 145], [77, 255, 255]],
# 	'RandY':[[0, 30, 50], [35, 255, 255]]
# }
thread=-1
# thread=9000  #ç»¿è‰²åƒç´ å€¼çš„é™åˆ¶ï¼Œåƒç´ ä½äºè¿™ä¸ªå€¼ä¼šè¢«ç­›é€‰
#20000


"""
æ‘„åƒå¤´å¼€å¯
"""
# 3264 2464  
def gstreamer_pipeline(
        capture_width=1280,
        capture_height=960,
        display_width=1280,
        display_height=960,
        framerate=21,
        flip_method=0,
):
    return (
            "nvarguscamerasrc ! "
            "video/x-raw(memory:NVMM), "
            "width=(int)%d, height=(int)%d, "
            "format=(string)NV12, framerate=(fraction)%d/1 ! "
            "nvvidconv flip-method=%d ! "
            "video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! "
            "videoconvert ! "
            "video/x-raw, format=(string)BGR ! appsink"
            % (
                capture_width,
                capture_height,
                framerate,
                flip_method,
                display_width,
                display_height,
            )
    )




"""
åŠ¨æ€å‚æ•°è§£æå‡½æ•°
"""
def cb(config,level):
    global lowerline
    global upperline
    global thread
    global Slowergreen
    global Shighgreen
    global color_dict
    Slowergreen[0]=config.H1
    Slowergreen[1]=config.S1
    Slowergreen[2]=config.V1
    Shighgreen[0]=config.H2
    Shighgreen[1]=config.S2
    Shighgreen[2]=config.V2
    print(Slowergreen)
    print(Shighgreen)

    # color_dict["Green"][0][0]=config.H1
    # color_dict["Green"][0][1]=config.S1
    # color_dict["Green"][0][2]=config.V1
    # color_dict["Green"][1][0]=config.H2
    # color_dict["Green"][1][1]=config.S2
    # color_dict["Green"][1][2]=config.V2
    # thread = config.thread

    # print(lowerline)

    # global kernel_size
    # kernel_size=config.Kernel_size
    # global threshofwhite 
    # threshofwhite = config.ThreshOfWhite

    return config

def shiftArea(img):
    row, column, _ = img.shape
    temp_img = img[int(row*0.2):int(row), int(column*0.2):int(column*0.8)]
    return temp_img

# æ ¹æ®ä¼ å…¥çš„colorï¼Œä»color_dictä¸­è·å–å¯¹åº”ä¸Šä¸‹é™æå–å¯¹åº”çš„é¢œè‰²
def getColorArea(img, color):
    hsv_img = cv2.cvtColor(temp_img, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv_img, lowerb=np.array(color_dict[color][0]), upperb=np.array(color_dict[color][1])) 
    color_img = cv2.bitwise_and(temp_img,temp_img, mask = mask)
    return color_img


"""
è§†è§‰å¤„ç†ä½¿ç”¨çš„å‡½æ•°å®šä¹‰åŒºâ€”â€”ä¸»è¦æ˜¯å¼¯é“
"""
FOV_w=105
flag = 0
pianyi_before = 0
cnt=0

def pianyi_detect(img):
    """
    å‚æ•°è°ƒè¯•åŒº
    """


    pianyi=0
    pianyi_text=''
    global pianyi_before
    global cnt
    ##############è¯»å–å›¾åƒ#########################
    (img_w, img_h) = img.shape[:2] #è·å–ä¼ å…¥å›¾ç‰‡çš„é•¿ä¸å®½   wæ˜¯é«˜ hæ˜¯å®½

    lane_img=img.copy() #å¤åˆ¶ä¸€ä»½è·å–çš„å›¾åƒç»™lane_img
    cropped_img=region_of_interest(lane_img) #å¯¹å›¾åƒè¿›è¡ŒROIçš„åˆ†å‰²
    # if cnt==0:
    #     cv2.imwrite('/home/cquer/2023_qingzhou/src/qz_vision/cropped_img.jpg',cropped_img)
    #     cnt+=1
    cropped_img_1=cropped_img.copy() #å°†ROIå›¾åƒå¤åˆ¶ä¸€ä»½ç»™cropped_img_1
    cropped_img = color_seperate(cropped_img) #å°†ROIå›¾åƒä¸­çš„ç»¿è‰²éƒ¨åˆ†æå–å‡ºæ¥
    gray_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY) #å°†æå–çš„  ROIçš„ç»¿è‰²éƒ¨åˆ†è½¬åŒ–ä¸ºç°åº¦å›¾
    ####1.å¦‚æœæ£€æµ‹åˆ°ç»¿è‰²çº¿æˆ–è€…ç»¿ç™½çº¿ï¼Œè¿›è¡Œåˆ¤æ–­###########
    ret, img_thresh = cv2.threshold(gray_img,10, 255, cv2.THRESH_BINARY)  #å¤§äº10çš„åœ°æ–¹å°±è½¬åŒ–ä¸ºç™½è‰²255ï¼Œè¿”å›ä¸¤ä¸ªå€¼ç¬¬ä¸€ä¸ªæ˜¯åŸŸå€¼ï¼Œç¬¬äºŒä¸ªæ˜¯äºŒå€¼å›¾å›¾åƒ
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (4, 4)) #è¿”å›ä¸€ä¸ª4*4çš„æ¤­åœ†å½¢çŸ©é˜µæ ¸ï¼Œæ¤­åœ†çš„åœ°æ–¹æ˜¯1ï¼Œå…¶ä»–åœ°æ–¹æ˜¯0
    img_thresh = cv2.morphologyEx(img_thresh, cv2.MORPH_CLOSE, kernel) #é—­è¿ç®—ï¼Œè¿ç”¨æ ¸kernelå…ˆè¿›è¡Œè†¨èƒ€ï¼Œå†è¿›è¡Œè…èš€
    img_thresh = cv2.morphologyEx(img_thresh, cv2.MORPH_OPEN, kernel) #å¼€è¿ç®—ï¼Œè¿ç”¨æ ¸kernelå…ˆè¿›è¡Œè…èš€ï¼Œå†è¿›è¡Œè†¨èƒ€
    contours, hierarchy = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # print(len(contours))#findcontoursè¿”å›ä¸¤ä¸ªå€¼ï¼Œä¸€ä¸ªæ˜¯ä¸€ç»„è½®å»“ä¿¡æ¯ï¼Œè¿˜æœ‰ä¸€ä¸ªæ˜¯æ¯æ¡è½®å»“å¯¹åº”çš„å±æ€§
    #####é¡ºå¸¦æ£€æµ‹è“è‰²è½¦é“çº¿###########
    cropped_img_1 = color_seperate_1(cropped_img_1)
    gray_img_blue = cv2.cvtColor(cropped_img_1, cv2.COLOR_BGR2GRAY)
    ret, img_thresh_blue = cv2.threshold(gray_img_blue, 10, 255, cv2.THRESH_BINARY)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    img_thresh_blue = cv2.morphologyEx(img_thresh_blue, cv2.MORPH_OPEN, kernel)
    img_thresh_blue = cv2.morphologyEx(img_thresh_blue, cv2.MORPH_CLOSE, kernel)
    contours_blue, hierarchy = cv2.findContours(img_thresh_blue, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if (len(contours_blue) > 0):
        contours_blue_2 = []
        for c1 in range(len(contours_blue)):
            for c2 in range(len(contours_blue[c1])):
                contours_blue_2.append(contours_blue[c1][c2])
        contours_blue_2 = np.array(contours_blue_2)
        (x2, y2, w2, h2) = cv2.boundingRect(contours_blue_2)
    nothing_point = 0 #æ— ç”¨çš„ç‚¹
    if (len(contours) > 0):   # å¦‚æœæ£€æµ‹åˆ°çš„è½®å»“æ•°é‡å¤§äº0
        con_num = len(contours) #å°†è½®å»“çš„ä¸ªæ•°èµ‹å€¼ç»™con_num
        contour1 = [] #å°†contour1 èµ‹å€¼ä¸ºç©ºåˆ—è¡¨ï¼Œ[]è¡¨ç¤ºåˆ—è¡¨ï¼Œåˆ—è¡¨æ˜¯å¯å˜çš„åºåˆ—
        for c1 in range(len(contours)): #éå†æ¯ä¸€ä¸ªè½®å»“
                for c2 in range(len(contours[c1])): #éå†æ¯ä¸€ä¸ªè½®å»“çš„è½®å»“ä¸Šçš„ç‚¹
                    contour1.append(contours[c1][c2]) #å°†æ¯ä¸€ä¸ªè½®å»“çš„æ¯ä¸€ä¸ªç‚¹éƒ½æ’åˆ—èµ·æ¥ç»„æˆä¸€ä¸ªæ–°åˆ—è¡¨ï¼Œ.append() æ–¹æ³•ç”¨äºåœ¨åˆ—è¡¨æœ«å°¾æ·»åŠ æ–°çš„å¯¹è±¡
        contour1 = np.array(contour1) #å°†ç»„æˆçš„æ–°åˆ—è¡¨è½¬åŒ–ä¸ºçŸ©é˜µï¼Œæ–¹ä¾¿ä¸‹ä¸€æ­¥å¤„ç†
        (x, y, w, h) = cv2.boundingRect(contour1) #ç”¨ä¸€ä¸ªæœ€å°çš„çŸ©å½¢ï¼ŒæŠŠæ‰¾åˆ°çš„æ‰€æœ‰çš„è½®å»“åŒ…èµ·æ¥ï¼Œè¿”å›è½®å€¼xï¼Œyæ˜¯çŸ©é˜µå·¦ä¸Šç‚¹çš„åæ ‡ï¼Œwï¼Œhæ˜¯çŸ©é˜µçš„å®½å’Œé«˜
        # ####################1.1 åŒæ—¶æ£€æµ‹åˆ°ä¸¤æ¡ç»¿çº¿ï¼Œåˆ é€‰å‡ºä¸­é—´çº¿ï¼Œè®¡ç®—ä½ç½®########################
        if w>img_h/3  and con_num > 1 : #å¦‚æœæ•´ä½“è½®å»“çš„å®½åº¦å¤§äºä¸‰åˆ†ä¹‹å›¾ç‰‡çš„å®½åº¦ï¼Œåˆ™è¯´æ˜åŒæ—¶æ£€æµ‹åˆ°äº†ä¸¤æ¡ç»¿çº¿

            mask=np.zeros_like(gray_img) 
            #å°†maskçš„éƒ¨åˆ†è¿›è¡Œç™½è‰²å¡«å……ï¼Œ
            # å‚æ•°ä¸ºå¡«å……åŒºåŸŸçš„å·¦ä¸Šè§’é¡¶å°†gray_imgè½¬åŒ–ä¸ºå…¨æ˜¯0çš„çŸ©é˜µå¹¶èµ‹å€¼ç»™maskå³å…¨é»‘ç‚¹å’Œå³ä¸‹è§’é¡¶ç‚¹
            cv2.rectangle(mask, (x+(3*w)//4, y), (x + w, y + h-3), (255, 255, 255), cv2.FILLED) 

             #å°†ä¼˜åŒ–åçš„äºŒå€¼å›¾img_threshä¸­çš„maskåŒºåŸŸæå–å‡ºæ¥ç»™temp_img
            temp_img=cv2.bitwise_and(img_thresh, img_thresh, mask=mask)

             #å¯¹åªå‰©ä¸‹ä¸­é—´çº¿çš„äºŒå€¼å›¾å›¾åƒè¿›è¡Œè½®å»“æ£€æµ‹   ï¼ˆå¸Œæœ›æ˜¯ä¸­é—´çº¿ï¼‰
            contours1, hierarchy = cv2.findContours(temp_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if (len(contours1) > 0):
                contour2 = []
                for c1 in range(len(contours1)):
                    for c2 in range(len(contours1[c1])):
                        contour2.append(contours1[c1][c2])
                contour2 = np.array(contour2) #å°†ä¸­é—´çº¿çš„è½®å»“ä¿¡æ¯å­˜äºcontour2çŸ©é˜µä¸­
                (x1, y1, w1, h1) = cv2.boundingRect(contour2) #ä¸­é—´çº¿çš„è½®å»“ä¿¡æ¯
                if con_num > 2 : #å·¦è¾¹ç»¿çº¿æ—¶ä¼šçœ‹ä¸æ¸…ï¼Œæ–­æˆä¸¤èŠ‚
                    cv2.rectangle(img, (x1, y1), (x1 + w1, img_h), (255, 255, 255), 3)#ç™½æ¡†-----åŒæ—¶æ£€æµ‹åˆ°ç»¿çº¿å’Œç»¿ç™½çº¿ç»™è“ç™½çº¿ç”»ç™½æ¡†â€”â€”æ°¸è¿œè´´ç€åº•ç”»çŸ©å½¢æ¡†
                    pianyi=((x1+w1/2)-(img_h/2))*FOV_w/img_h #pianyiå€¼ä¸ºçŸ©å½¢æ–¹æ¡†çš„ä¸­çº¿è·ç¦»è§†é‡ä¸­å¤®çš„å®é™…è·ç¦»
                    if pianyi>0:
                        pianyi_text='right'
                    elif pianyi<0:
                        pianyi_text='left'
                        # pianyi+=80
                    else:
                        pianyi_text = 'stright'
                    # é˜²æ­¢è½¦è¿›å¼¯é“æ—¶è¿‡äºé è¿‘ç»¿çº¿
                    if  len(contours_blue)>0 and np.sum(img_thresh_blue)<10000 and  pianyi_text == 'right':
                        pianyi = pianyi // 3
                        print('é˜²æ­¢è½¦è¿›å¼¯é“æ—¶è¿‡äºé è¿‘ç»¿çº¿')
                        # print(np.sum(img_thresh_blue))
                    print(1,pianyi_text)
                else : #è¿™ä¸ªæ—¶å€™æ‰æ˜¯çœŸæ­£çš„ç»¿çº¿
                    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 3) #è“æ¡†-----------------åªæ£€æµ‹åˆ°è“çº¿å¹¶ç”¨è“æ¡†ç”»å‡º
                    pianyi = -83+((x + w / 2) - (img_h / 2)) * FOV_w / img_h #80å‡‘æ•°,ä¸ºäº†è®©è½¦ä¸å¼€å‡ºèµ›é“å»
                    pianyi_text='right'
                    print(2,pianyi_text)
        #########################1.2 åªæ£€æµ‹åˆ°ä¸€æ¡çº¿ï¼Œéœ€è¦åˆ¤æ–­æ˜¯ç»¿ç™½çº¿è¿˜æ˜¯ç»¿çº¿##############
        elif w<img_h/3  :
            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 255), 3) #é»„æ¡†----------åªæ£€æµ‹åˆ°ç»¿ç™½çº¿å¹¶ç”¨é»„æ¡†ç”»å‡º
            # å¦‚æœæ˜¯ç»¿ç™½çº¿
            if con_num>1: #è½®å»“æ•°é‡å¤§äº1ï¼Œå°±æ˜¯æœ‰å¥½å‡ æ®µç»¿è‰²,ä½†æ˜¯ä¼šå‡ºç°è¾¹çº¿è¯¯è¯†åˆ«æˆä¸­çº¿ï¼Œå› ä¸ºçº¿å¯èƒ½ä¼šæ–­æ‰ï¼Ÿ
                pianyi = ((x + w / 2) - (img_h / 2)) * FOV_w / img_h #pianyiå€¼ä¸ºçŸ©å½¢æ–¹æ¡†çš„ä¸­çº¿è·ç¦»è§†é‡ä¸­å¤®çš„å®é™…è·ç¦»
                if pianyi > 0:
                    #print('å³å')
                    pianyi_text='right'
                elif pianyi<0:
                    #print('å·¦å')
                    pianyi_text='left'
                    pianyi -= 80
                else:
                    # print('å·¦å')
                    pianyi_text = 'stright'
                print(3,pianyi_text)
            # å†åˆ†ç±»
            else: 
                #  å°ç»¿ç™½çº¿
                if h < 50 and len(contours_blue)>0 and x>50:
                    pianyi = ((x + w / 2) - (img_h / 2)) * FOV_w / img_h #pianyiå€¼ä¸ºçŸ©å½¢æ–¹æ¡†çš„ä¸­çº¿è·ç¦»è§†é‡ä¸­å¤®çš„å®é™…è·ç¦»
                    print(4,pianyi_text)
                    if pianyi > 0:
                        pianyi_text='right'
                    elif pianyi<0:
                        pianyi_text='left'
                    else:
                        pianyi_text = 'stright'            
                # çœŸè¾¹ç»¿çº¿,ä¹‹çœ‹è§å·¦è¾¹çš„ç»¿è‰²çº¿
                else:
                    pianyi = -83+((x + w / 2) - (img_h / 2)) * FOV_w / img_h
                    pianyi_text='right'
                    print(5,pianyi_text)
        elif con_num == 1: #æ¨ªå‘ç»¿çº¿å’Œæœ€åä¸€å°æ®µç»¿ç™½çº¿çš„ç»¿çº¿
                if h < 50 and len(contours_blue)>0 and x>50:
                    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 255), 3) #é»„æ¡†----------------æ£€æµ‹åˆ°äº†æœ€åä¸€å°æ®µçš„è“ç™½çº¿çš„è“è‰²
                    pianyi = ((x + w / 2) - (img_h / 2)) * FOV_w / img_h
                    print(7,pianyi_text)
                    if pianyi > 0:
                        #print('å³å')
                        pianyi_text='right'
                    elif pianyi<0:  
                        #print('å·¦å')
                        pianyi_text='left'
                    else:
                        # print('å·¦å')
                        pianyi_text = 'stright'
                else: #çœ‹è§ä¸€å—ç»¿è‰²å¹¶ä¸”çœŸçš„æ˜¯ç»¿çº¿
                    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 3) #è“æ¡†-----------------åªæ£€æµ‹åˆ°ç»¿çº¿å¹¶ç”¨è“æ¡†ç”»å‡º
                    pianyi = -100+((x + w / 2) - (img_h / 2)) * FOV_w / img_h #å¹³æ»‘è¿‡æ¸¡
                    pianyi_text='right'
                    print(8,pianyi_text)
        else : #æ£€æµ‹åˆ°äº†å·¦ä¸‹è§’çš„ç‚¹äº†
            nothing_point = 1


    # 2.æœªæ£€æµ‹åˆ°ç»¿çº¿æˆ–è€…ç»¿ç™½çº¿ï¼Œå°±æ£€æµ‹è“çº¿
    else:
        if len(contours_blue)>0:
            if (x2+w2/2)>(2*img_h)/3:
                cv2.rectangle(img, (x2, y2), (x2 + w2, img_h), (255, 0, 255), 3) #çº¢æ¡†
                if h2 < 70:
                    pianyi = pianyi_before
                    print(9)
                else :
                    pianyi = 200 - ((x2 + w2 / 2) - (img_h / 2)) * FOV_w / img_h
                    pianyi_text='left'
                    print(10,pianyi_text)

    show_img = img

    pianyi_now = abs(pianyi)

    angle_gain_left = 80 # è¿™ä¸ªå€¼éšé€Ÿåº¦å˜åŒ–ï¼Œé€Ÿåº¦0.3å·®ä¸å¤šå¯¹åº”40çš„angle_gain
    angle_gain_right = 80
    if pianyi_text == 'right' :
        pianyi_now = 0 - pianyi_now -  angle_gain_right

    elif  pianyi_text == 'left' :
        pianyi_now =  pianyi_now + angle_gain_left

    #  
    if pianyi_before == -pianyi_now or nothing_point ==1 : #è¿™ä¸€å¥å¦‚æœåŠ ä¸Šé˜²æ­¢çªå˜æœ‰ç‚¹å±é™©
        pianyi_now = pianyi_before       
        print("*****æ£€æµ‹åˆ°å¹²æ‰°*******")   
    pianyi_before = pianyi_now
    # print('-------------------',pianyi_now )
    return pianyi_now, show_img




# #####################æå–ROI#############################
def region_of_interest(r_image):
    h = r_image.shape[0] #å›¾ç‰‡çš„é«˜
    w = r_image.shape[1] #å›¾ç‰‡çš„å®½
    ImgH_=180  #90
    gray = cv2.cvtColor(r_image, cv2.COLOR_BGR2GRAY) #è½¬åŒ–ä¸ºç°åº¦å›¾

    poly = np.array([
        [(0, h-ImgH_), (w, h-ImgH_), (w, h), (0, h)]  #å°†æ•°ç»„è½¬åŒ–ä¸ºçŸ©é˜µï¼Œå››ä¸ªä¸ºé•¿æ–¹å½¢çš„å››ä¸ªé¡¶ç‚¹ï¼Œä»å·¦ä¸Šè§’å¼€å§‹é¡ºæ—¶é’ˆ,æœ€ä¸‹é¢ç«–ç€100ä¸ªåƒç´ çš„å›¾ #åŸæ¥æ˜¯90
    ])
    mask = np.zeros_like(gray) #è¾“å…¥ä¸ºçŸ©é˜µgrayï¼Œè¾“å‡ºä¸ºå½¢çŠ¶å’Œgrayä¸€è‡´çš„çŸ©é˜µï¼Œå…¶å…ƒç´ å…¨éƒ¨ä¸ºé»‘è‰²0
    cv2.fillPoly(mask, poly, 255)   #å°†maskçš„polyéƒ¨åˆ†å¡«å……ä¸ºç™½è‰²255
    masked_image = cv2.bitwise_and(r_image,r_image, mask=mask)  #å°†r_imageçš„maskåŒºåŸŸæå–å‡ºæ¥ç»™masked_image
    return masked_image

# ###############################greenåˆ†å‰²############################
def color_seperate(image):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)   #å¯¹ç›®æ ‡å›¾åƒè¿›è¡Œè‰²å½©ç©ºé—´è½¬æ¢
    lower_hsv = Slowergreen          #è®¾å®šgreenä¸‹é™
    upper_hsv = Shighgreen        #è®¾å®šgreenä¸Šé™
    mask = cv2.inRange(hsv, lowerb=lower_hsv, upperb=upper_hsv)  #ä¾æ®è®¾å®šçš„ä¸Šä¸‹é™å¯¹ç›®æ ‡å›¾åƒè¿›è¡ŒäºŒå€¼åŒ–è½¬æ¢ï¼Œä½äºlower,é«˜äºupperéƒ½å˜æˆ0ï¼Œåœ¨ä¸­é—´ä¸º255
    dst = cv2.bitwise_and(image, image, mask=mask)    #å°†imageçš„maskåŒºåŸŸæå–å‡ºæ¥ç»™dst,å³æ‰¾åˆ°è“è‰²åŒºåŸŸå¹¶èµ‹å€¼ç»™dst
    return dst


# ############################blueåˆ†å‰²##############################
def color_seperate_1(image):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)   #å¯¹ç›®æ ‡å›¾åƒè¿›è¡Œè‰²å½©ç©ºé—´è½¬æ¢
    lower_hsv = np.array([100, 43, 46])          
    upper_hsv = np.array([160, 255, 255])        
    mask = cv2.inRange(hsv, lowerb=lower_hsv, upperb=upper_hsv)  #ä¾æ®è®¾å®šçš„ä¸Šä¸‹é™å¯¹ç›®æ ‡å›¾åƒè¿›è¡ŒäºŒå€¼åŒ–è½¬æ¢ï¼Œä½äºlower,é«˜äºupperéƒ½å˜æˆ0ï¼Œåœ¨ä¸­é—´ä¸º255
    dst = cv2.bitwise_and(image, image, mask=mask)    #å°†imageçš„maskåŒºåŸŸæå–å‡ºæ¥ç»™dst,å³æ‰¾åˆ°çº¢è‰²åŒºåŸŸå¹¶èµ‹å€¼ç»™dst
    # cv2.imshow('red', dst)  #æŸ¥çœ‹çº¢è‰²åŒºåŸŸçš„å›¾åƒ
    # # cv2.waitKey(3)
    return dst



# åºŸå¼ƒ
def getRoadLineThroughHSV(img):
    hsv_img=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)
    mask1=cv2.inRange(hsv_img,lowerwhite,upperwhite)
    # mask2=cv2.inRange(hsv_img,lowerwhite,upperwhite)

    masked_img1=cv2.bitwise_and(img,img,mask=mask1)
    # masked_img2=cv2.bitwise_and(img,img,mask=mask2)
    # masked_img=masked_img1+masked_img2
    masked_img=masked_img1

    gray_img=cv2.cvtColor(masked_img,cv2.COLOR_BGR2GRAY)
    ret,binary_img=cv2.threshold(gray_img,10,255,cv2.THRESH_BINARY)
    # kernel1=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))
    # kernel2=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(2,2))
    # binary_img=cv2.morphologyEx(binary_img,cv2.MORPH_OPEN,kernel2)
    # binary_img=cv2.morphologyEx(binary_img,cv2.MORPH_CLOSE,kernel1)

    return binary_img

# åºŸå¼ƒ
def getLineCenter(binary_img):
    shift=0
    cx=0
    lastcx=0
    cy=0
    lastcy=0
    count=0
    
    # histogram=np.sum(binary_img[:,:],axis=0)
    # midpoint = int(histogram.shape[0] / 2)
    # leftx_base = np.argmax(histogram[:midpoint])
    # rightx_base = np.argmax(histogram[midpoint + 30:])
    # if leftx_base != 0 and rightx_base != 0:
    # 	base = leftx_base + 30
    # else:
    # 	base = rightx_base + midpoint + 30
    
    # histogram2=np.sum(binary_img[:,:],axis=1)
    # midpoint2 = int(histogram2.shape[0] / 2)
    # lefty_base = np.argmax(histogram2[:midpoint2])
    # righty_base = np.argmax(histogram2[midpoint2 + 30:])
    # if lefty_base != 0 and righty_base != 0:
    # 	base2 = lefty_base + 30
    # else:
    # 	base2 = righty_base + midpoint2 + 30




    final_img=binary_img
    # final_img=binary_img[:img.shape[0]-base2,:base]
    contours=cv2.findContours(final_img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
    contours=contours[0]
    if len(contours)>0:
        M = cv2.moments(contours[0])
        lastcx=cx
        lastcy=cy
        cx = int(M['m10']/(M['m00']+float("1e-5")))   # åŠ ä¸Šfloaté˜²æ­¢é™¤æ•°å¯èƒ½ä¸ºé›¶çš„æƒ…å†µ
        cy = int(M['m01']/(M['m00']+float("1e-5")))
        # é˜²æ­¢æŠ½æ
        if count>=5:
            if abs(cx-lastcx)>binary_img.shape[1]//2:
                cx=lastcx
            if abs(cy-lastcy)>binary_img.shape[0]//5:
                cy=lastcy
        count+=1
        # cv2.line(final_img,(cx,cy),(final_img.shape[1]//2,final_img.shape[0]),(0,0,0),thickness=5)
        # é˜²æ­¢ä¸­é—´æœ‰æ—¶å€™å¤„ç†æœ‰é—®é¢˜å¯¼è‡´æ‰¾ä¸åˆ°ä¸­ç‚¹ï¼ŒåŒæ—¶åœ¨å‡ºå¼¯æ—¶å¯ä»¥ç”¨æ¥åˆ¤æ–­
        if cx == 0 and cy == 0:
            shift = 0
        else:
            shift = np.degrees(np.arctan(float(50+binary_img.shape[1]/2 - cx)/float( binary_img.shape[0]-cy)))/(-57.3)
    # cv2.imwrite("/home/cquer/2023_qingzhou/src/qz_vision/final.jpg",final_img)
    return shift,final_img
# æå–ç™½è‰²è½¦é“å¿
def getWhiteLine(img):
    gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    ret,binary_img=cv2.threshold(gray_img,threshofwhite,255,cv2.THRESH_BINARY)
    kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(kernel_size,kernel_size))
    binary_img=cv2.morphologyEx(binary_img,cv2.MORPH_OPEN,kernel)
    binary_img=cv2.morphologyEx(binary_img,cv2.MORPH_CLOSE,kernel)
    return binary_img
# åºŸå¼ƒ
def blackBlock(img):
    # cut off img
    # img_cut = getROI(img)
    img_cut=img
    # erzhihua here
    colorFlip = cv2.cvtColor(img_cut, cv2.COLOR_BGR2HSV)
    lower_bound = (0, 0, 0)
    upper_bound = (10, 50, 255)
    mask = cv2.inRange(colorFlip, lower_bound, upper_bound)
    # Dilation & Opening
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    # find positon
    positions = cv2.findNonZero(mask) # containing all black blocks
    # find the largest one

    return positions

# ç‹ç‚æå‡ºçš„å¯»æ‰¾å†…ç©ºæ´å¹¶ä¸”è®¡ç®—å›¾å¿ƒçš„ç®—æ³•,é‡‡ç”¨
def FindBlueCenterLine(binary_img,img,defalt_pos):
    delta_x=binary_img.shape[1]//6
    # position=defalt_pos

    conters=cv2.findContours(binary_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[0]
    Appropriate_M=[]
    last_area=0
    if len(conters)>0:
        for c in conters:
            M=cv2.moments(c)
            if M['m00']>10:
                if M['m00']<10000:
                    if M['m00']>last_area:
                        last_area=M['m00']
                        img=cv2.drawContours(img,c,-1,(0,0,255),3)
                        Appropriate_M.append((int(M['m10']/(M['m00']+float("1e-5"))),int(M['m01']/(M['m00']+float("1e-5")))))
    if len(Appropriate_M)>0:
        pt = Appropriate_M[-1]
        if delta_x>abs(pt[0]-defalt_pos[0]):
            position=pt
            # delta_x=abs(pt[0]-binary_img.shape[1]//2)
        # for pt in Appropriate_M:
        else:
            position = ((1*pt[0])//16+(15*defalt_pos[0])//16,(1*pt[1])//16+(15*defalt_pos[1])//16)
    else:
        position=defalt_pos
    
    cv2.line(img,position,(img.shape[1]//2,img.shape[0]),(255,0,0),thickness=5)

    x=position[0]
    y=position[1]
    shift = np.degrees(np.arctan(float(binary_img.shape[1]/2 - x)/float(float("1e-5") + binary_img.shape[0]-y)))/(-57.3)
    # vel=(binary_img.shape[0]-y)*0.001+0.05
    vel=0.3

    return img,position,shift,vel

# å‡ºå¼¯åˆ¤æ–­å‡½æ•°ï¼Œå¯»æ‰¾è½¦é“çº¿ 
def FindBlueBlockWhenYouWantKonwOutOfRoadLineOrNot(img):
    lower_hsv = np.array([100, 43, 46])          
    upper_hsv = np.array([160, 255, 255]) 
    hsv_img=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)

    mask=cv2.inRange(hsv_img,Slowergreen,Shighgreen)
    masked_img=cv2.bitwise_and(img,img,mask=mask)

    mask_blue = cv2.inRange(hsv_img,lower_hsv,upper_hsv)
    mask_blue_img = cv2.bitwise_and(img,img,mask=mask_blue)

    gray_img=cv2.cvtColor(masked_img+mask_blue_img,cv2.COLOR_BGR2GRAY)
    _,binary_img=cv2.threshold(gray_img,50,255,cv2.THRESH_BINARY)
    kernel1=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(2,2))
    kernel2=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(2,2))
    binary_img=cv2.morphologyEx(binary_img,cv2.MORPH_OPEN,kernel2)
    binary_img=cv2.morphologyEx(binary_img,cv2.MORPH_CLOSE,kernel1)
    # print(np.sum(binary_img))
    if np.sum(binary_img)>1200000:
        return True,binary_img
    else:
        return False,binary_img

"""
æ–‡å­—è¯†åˆ«åŒº
"""
def do_recog():
    return 'p1'


"""
å›è°ƒå‡½æ•°
"""
def OdomCallBack(msg):
    global	pub_flag,recog_flag,dwa_flag,turn_on_recog_flag_flag,turn_on_dwa_flag_flag
    x = msg.pose.pose.position.x
    y = msg.pose.pose.position.y
    # çº¢ç»¿ç¯çš„ä¸€ä¸ªå¤ä½æ ‡å¿—ä½
    if y<-4.8:
        pub_flag=1
        turn_on_recog_flag_flag=True
        turn_on_dwa_flag_flag=True
    # å¼€å¯è¯†åˆ«å—ï¼Ÿ
    # åˆ°è¾¾ä½ç½®ä¸”æœªå‘é€åœè½¦åŒºFLAGæ‰å…è®¸ç½®ä½
    #-1.4   -2.0
    if x<-1.0 and y>-1.0 and turn_on_recog_flag_flag:
        recog_flag=True
    # å¼€å¯DWAå—
    # DWAçš„FLAGåªä¼šåœ¨Så¼¯ç»“æŸå¤ä½æ—¶å¤ä½ï¼Œæ­¤åä¸å†å‘å¸ƒæ¶ˆæ¯
    if x<-1.0 and y>-1.0 and roadlineflag and turn_on_dwa_flag_flag:
        dwa_flag=True
        print("---------DWA å¯åŠ¨ï¼[qz_vision]-----------------------")
    return 0

Queue=queue.LifoQueue()
def LoacateCB(msg):
    global roadlineflag
    global	break_flag
    global queue_out
    if msg.data==4:
        roadlineflag=True
        Queue.put('line')
        # queue_out='line'
    elif msg.data == 1:
        break_flag=False
        Queue.put('traffic')
        # queue_out='traffic'

    

if __name__=="__main__":
    rospy.init_node("qz_vision")

    """
    åŠ¨æ€å‚æ•°
    """
    # server = Server(detector_dynamicConfig,cb)

    """
    ROSæ¥å£åŒº
    """
    # detect()
    # qz_cmd_vel_vision  è°ƒè¯•å®Œè¯é¢˜æ¢æˆè¿™ä¸ª
    move_pub=rospy.Publisher("/qz_cmd_vel_vision",Twist,queue_size=1)
    
    locate_sub=rospy.Subscriber("/qingzhou_locate",std_msgs.Int32,LoacateCB)
    # locate_pub=rospy.Publisher("/qingzhou_locate",std_msgs.Int32,queue_size=1)
    traffic_flag = rospy.Publisher("/traffic_flag",std_msgs.Int32,queue_size=1)
    park_id_=rospy.Publisher("/Park_id",std_msgs.Int32,queue_size=1)
    dwa_flag_=rospy.Publisher("/dwa_flag",std_msgs.Int32,queue_size=1)
    filter_dwa_flag_=rospy.Publisher("/filter_dwa_flag",std_msgs.Int32,queue_size=1)
    odom_sub = rospy.Subscriber("/amcl_pose",PoseWithCovarianceStamped,OdomCallBack)
    # æ˜¾ç¤ºç”¨å‘å¸ƒè€…
    traffic_pub=rospy.Publisher("/TrafficImg",Image,queue_size=5)
    bianry_pub=rospy.Publisher("/BinaryImg",Image,queue_size=5)
    RoadLine_Pub = rospy.Publisher("/RoadLinePub",Image,queue_size=5)
    raw_pub = rospy.Publisher("/RawImg",Image,queue_size=5)


    """
    å‚æ•°åŒº
    """
    
    #Så¼¯é“ä½¿ç”¨çš„å‚æ•° 
    cou=0
    Kp, Kd, Ki = 2.0, 0.1,0.5
    D_shift=[0, 0, 0]
    angle=0
    now_shift=0
    last_shift =  0
    outcheck = 0


    #çº¢ç»¿ç¯ä½¿ç”¨çš„å‚æ•°
    green_count=0
    notgreen_count=0	
    color_flag=0 
    dict=cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_1000)
    parameters =  cv2.aruco.DetectorParameters_create()
    start_time =0
    end_time =0
    
    # pianyibefore = 0
    wheelbase = 0.31
    pianyicount = 0
    pianyisamelist = [0,0,0,0,0,0,0]#å¤§æ¦‚éœ€è¦4/40=0.1såˆ¤æ–­è½¦è½¦æœ‰æ²¡æœ‰å‡ºå»ï¼Œå¯èƒ½å¤ªçŸ­äº†
    controlFlag = 10 #åŸæ¥æ˜¯10
    openColorDetector = 0 #åŸæ¥æ˜¯0
    global flag_traffic
    flag_traffic = 0
    redtime = 0
    acc = -0.1
    v = 0.5
    cmdData = Twist()


    det = Detect()
    cam=cv2.VideoCapture(gstreamer_pipeline(flip_method=0),cv2.CAP_GSTREAMER) 
    # ç¨‹åºä¼šåœ¨è¿™é‡Œé˜»å¡ è°ƒè¯•è§†è§‰æ—¶å…³æ‰ï¼Œä¹‹åè®°å¾—å¼€å¯
    print("æ¬§å°¼é…±ï¼Œè§†è§‰å¼€å§‹äº†å“Ÿï½","FBI open the camera!------------------")
    while not rospy.is_shutdown():
        queue_out=Queue.get()   
        if (queue_out=="line" and roadlineflag):
            print("æ¬§å°¼é…±,Så¼¯å¼€å§‹äº†~")
            filter_dwa_flag_.publish(0)
            keep_count = 0  # å‰50å¼ å›¾ç‰‡å¿½ç•¥ä¸è®¡
            twist = 0
            twist_before = 0.026
            twist_count = 0
            while cam.isOpened():
                delta_time = end_time-start_time
                start_time = time.time()
                print("ç¨‹åºç”¨æ—¶ï¼š%.4f"%delta_time)
                # å‡ºå¼¯åˆ¤æ–­
                # *******************é‡ç‚¹ï¼šåˆ‡æ¢çŠ¶æ€æœºè‡³DWAå€’è½¦*******************
                # Så¼¯å‚æ•°å¤ä½
                # åˆ‡æ¢çŠ¶æ€è‡³TOSTART
                # ç»™å‡ºå¼€å¯DWAå¯¼èˆªçš„FLAG_DWAï¼Œåœ¨å®šä½å‡½æ•°ä¸­è¿›è¡Œ
                # ç”±å®šä½å¼€å¯æ–‡å­—è¯†åˆ«çš„å­ç¨‹åºï¼Œå¹¶æ ¹æ®è¯†åˆ«ç»“æœå‘å¸ƒåœè½¦ä½ç½®çš„FLAG_POS
                if outcheck == 10:
                    # å¤ä½
                    outcheck = 0
                    roadlineflag=False
                    dwa_flag=False
                    recog_flag = False
                    # åˆ‡æ¢çŠ¶æ€
                    # locate_pub.publish(5)
                    filter_dwa_flag_.publish(1)
                    print("æ¬§å°¼é…±ï¼ŒSå¼¯ç»“æŸäº†")
                    break
                ret, Img = cam.read()
                # å‡ºå¼¯å°åˆ¤æ–­ï¼Œæå–èµ›é“ï¼Œç¡®å®špixå€¼åŒºé—´ï¼Œä½äºæŸä¸ªå€¼åˆ™è®¤ä¸ºå‡ºåœˆ
                if ret:
                    if keep_count>=50:
                            FindLine, FindBlueBlockWhenYouWantKonwOutOfRoadLineOrNot_img = FindBlueBlockWhenYouWantKonwOutOfRoadLineOrNot(Img[Img.shape[0]//2+50:,:])                            
                            if FindLine:
                                outcheck = 0
                            else:
                                outcheck = 1
                    else:
                        # å‰50å¼ å›¾ç‰‡å¿½ç•¥ä¸è®¡
                        keep_count+=1
                # è®¡ç®—å¼¯é“è½¬è§’ä»¥åŠå‘å¸ƒå¯è§†åŒ–&è¿æ§  recog_flag and
                if  keep_count==70:
                    park_id = det.detect(Img)
                    print(park_id)
                    keep_count=50
                    if park_id=='hangtian' or park_id=='jidian':
                        park_id_.publish(1)
                        recog_flag=False
                        turn_on_recog_flag_flag=False
                    elif park_id=='xinghang' or park_id=='sanyuan':
                        park_id_.publish(2)
                        recog_flag=False
                        turn_on_recog_flag_flag=False
                else:
                    keep_count+=1
                    # è¯†åˆ«å¤±è´¥ï¼Œæ”¾å¼ƒå€’è½¦
                if ret and keep_count>=50:
                    Img_2 = cv2.resize(Img,(640,480))
                    Img_2 = Img_2[3: 475,3:635]  #åˆ‡å‰²æ‰å·¦å³ä¸‹è§’å¹²æ‰°ç‚¹
                    Img_2 = cv2.resize(Img_2,(640,480))
                    pianyi, show_img = pianyi_detect(Img_2)
                    twist = pianyi/7000
                    # twist *= wheelbase/v
                    # å¿½ç•¥å°è§’åº¦å˜åŒ–, å¹³æ»‘è½¨è¿¹
                    if abs(twist-twist_before) < 0.001:
                        twist = twist_before

                    if outcheck==10:
                        cmdData.angular.z=0
                        cmdData.linear.x = 0
                    else:
                        # cmdData.angular.z=0
                        # cmdData.linear.x = 0
                        cmdData.angular.z=twist
                        # print(cmdData.angular.z)
                        cmdData.linear.x = v
                    move_pub.publish(cmdData)
                    pianyi_before = pianyi
                    twist_before = twist
                    for index,value in enumerate(pianyisamelist):
                        if(not(index == len(pianyisamelist)-1)):#æ¯ä¸ªå…ƒç´ å¾€å‰ç§»åŠ¨
                            pianyisamelist[index] = pianyisamelist[index+1]
                        else:#åˆ—è¡¨æœ€åä¸€ä¸ªè¿›æ¥
                            pianyisamelist[index] = pianyi
                    if(len(set(pianyisamelist)) == 2):
                            pianyi = 999
                    final_img_msg=Image()
                    final_img_msg.header=std_msgs.Header()
                    final_img_msg.width=show_img.shape[1]
                    final_img_msg.height=show_img.shape[0]
                    final_img_msg.encoding="bgr8"
                    final_img_msg.step=1920
                    final_img_msg.data=np.array(show_img).tostring()
                    RoadLine_Pub.publish(final_img_msg)
                # ç”±å®šä½å¼€å¯æ–‡å­—è¯†åˆ«çš„å­ç¨‹åºï¼Œå¹¶æ ¹æ®è¯†åˆ«ç»“æœå‘å¸ƒåœè½¦ä½ç½®çš„FLAG_POS
                # ç»™å‡ºå¼€å¯DWAå¯¼èˆªçš„FLAG_DWAï¼Œåœ¨å®šä½å‡½æ•°ä¸­è¿›è¡Œ
                if dwa_flag:
                    dwa_flag_.publish(1)
                    turn_on_dwa_flag_flag=False
                    dwa_flag=False
                end_time = time.time()
                


                # binary2_msg=Image()
                # binary2_msg.header=std_msgs.Header()
                # binary2_msg.width=binary_img.shape[1]
                # binary2_msg.height=binary_img.shape[0]
                # binary2_msg.encoding="mono8"
                # binary2_msg.step=1920
                # binary2_msg.data=np.array(binary_img).tostring()
                # raw_pub.publish(binary2_msg)


        # not break_flag ï¼šbreak_flagç”¨äºåˆ¤æ–­æ˜¯å¦åœ¨æ‰§è¡ŒğŸ˜¡ç»¿ç¯ä»»åŠ¡çš„æ ‡å¿—ä½ï¼Œåœ¨LOADä¼šå˜æˆFALSEï¼Œå…è®¸æ‰§è¡Œ
        elif queue_out=="traffic" and (not break_flag):
            print("[INFO]---I am in the traffic now!!!")
            while cam.isOpened():
                # è¿™ä¸€åœˆçš„çº¢ç»¿ç¯æ£€æµ‹ä»»åŠ¡å½»åº•ç»“æŸ
                # æ£€æµ‹åˆ°äº†ç»¿ç¯ï¼Œå‘å¸ƒçŠ¶æ€æœºåˆ°TOUNLOADï¼Œå¤ä½
                if color_flag==1:
                        print("Green, you can go.")
                        # locate_pub.publish(8)
                        traffic_flag.publish(1)
                        break_flag=True
                        color_flag, green_count, notgreen_count = 0, 0, 0
                        break
                # æœªæ£€æµ‹åˆ°ç»¿ç¯ï¼Œå¤ä½ï¼Œä¿æŒçŠ¶æ€æœºåœ¨LOAD
                elif color_flag==2:
                        print("Red or yellow, stop.")
                        color_flag, green_count, notgreen_count = 0, 0, 0
                ret,img = cam.read()
                # print(img)
                if ret:
                    img = cv2.resize(img, None, fx = 0.5, fy = 0.5, interpolation = cv2.INTER_CUBIC)
                    if True:
                        # æˆªå–æœ‰ç”¨çš„åŒºåŸŸ
                        temp_img=shiftArea(img)
                        # è·å–çº¢è‰²é»„è‰²çš„è‰²å›¾(bushi)å’Œç»¿è‰²çš„è‰²å›¾(bushi)
                        green_Limg = getColorArea(temp_img, 'Green')
                        RandY_Limg = getColorArea(temp_img, 'RandY')

                        # gray_green = cv2.cvtColor(green_Limg,cv2.COLOR_BGR2GRAY)
                        # _,gray_green = cv2.threshold(gray_green,thread,255,cv2.THRESH_BINARY)
                        
                        #ç”±è®¾ç½®çš„é˜ˆå€¼threadç¡®å®šæ˜¯å¦ç»¿ç¯äº®é˜ˆå€¼ 
                        print("I am counting green   ------------   ",np.sum(green_Limg))
                        if np.sum(green_Limg) > thread:
                            green_count += 1
                        # elif np.sum(RandY_Limg) > thread:
                        else:
                            # print("I am counting not green")
                            notgreen_count += 1
                        # æ•°å…«æ¬¡å¦‚æœéƒ½æ˜¯ç»¿ç¯å°±ç»™ç»¿ç¯çš„æ ‡å¿—ä½
                        if green_count == 8:
                            color_flag = 1
                        elif notgreen_count == 8:
                            color_flag = 2

                        # traffic_msg=Image()
                        # header=std_msgs.Header()
                        # header.frame_id="Camera"
                        # traffic_msg.header=header
                        # traffic_msg.width=green_Limg.shape[1]
                        # traffic_msg.height=green_Limg.shape[0]
                        # traffic_msg.encoding="bgr8"
                        # traffic_msg.step=1920
                        # traffic_msg.data=np.array(green_Limg).tostring()
                        # traffic_pub.publish(traffic_msg)

                        # redmsg=Image()
                        # header=std_msgs.Header()
                        # header.frame_id="Camera"

                        # redmsg.header=header
                        # redmsg.width=RandY_Limg.shape[1]
                        # redmsg.height=RandY_Limg.shape[0]
                        # redmsg.encoding="bgr8"
                        # redmsg.step=1920
                        # redmsg.data=np.array(RandY_Limg).tostring()
                        # gray_pub.publish(redmsg)

                    # RVIZæ˜¾ç¤ºä¾¿äºè°ƒè¯•
                    # imgmsg=Image()
                    # header=std_msgs.Header()
                    # header.frame_id="Camera"

                    # imgmsg.header=header
                    # imgmsg.width=img.shape[1]
                    # imgmsg.height=img.shape[0]
                    # imgmsg.encoding="bgr8"
                    # imgmsg.step=1920
                    # imgmsg.data=np.array(img).tostring()
                    # # print("i am in the while loop")
                    # traffic_pub.publish(imgmsg)

        """
        OLDçš„Så¼¯é“
        """

        # if ret:
        # 	Img=Img[Img.shape[0]//2+50:,:]
        # 	FindLine,blueblock = FindBlueBlockWhenYouWantKonwOutOfRoadLineOrNot(Img)

        # 	if FindLine:
        # 		outcheck = 0
        # 	else:
        # 		outcheck += 1
        # 	# cv2.imwrite("/home/cquer/2023_qingzhou/src/qz_vision/RAW.jpg",Img)

        # 	binary_img=getWhiteLine(Img)
        # 	if cou==0:
        # 		defalt_pos=(binary_img.shape[1]//2,binary_img.shape[0]//2)
        # 	cou+=1
        # 	roallineFinalImg,position,shift,vel=FindBlueCenterLine(binary_img,Img,defalt_pos)
        # 	defalt_pos=position
            
            
            
        # 	if shift:
        # 		last_shift=now_shift
        # 		now_shift=shift
        # 		D_shift.append(shift)

        # 		angle=Kp*now_shift+Kd*(now_shift-last_shift)+Ki*(sum(D_shift)/len(D_shift))
        # 	else:
        # 		angle=0
        # 	# print(angle)
        # 	if outcheck==6:
        # 		cmdData.linear.x=0
        # 		cmdData.angular.z=0
        # 		locate_pub.publish(5)

        # 	else:
        # 		cmdData.linear.x=vel
        # 		cmdData.angular.z=angle*12
        # 	move_pub.publish(cmdData)
                        

    cam.release()
